\documentclass[10pt, twocolumn]{article}

\usepackage[a4paper, margin=0.5in]{geometry}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{xtab}
\usepackage{physics}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{seqsplit}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{braket}
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{pgfplots}
\usetikzlibrary{quantikz}

\DeclareMathOperator{\lcm}{lcm}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand*\diff{\mathop{}\!\mathrm{d}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{postulate}[theorem]{Postulate}
\newtheorem{problem}[theorem]{Problem}
\newtheorem*{claim}{Claim}


\usepackage[backend=biber, sorting=none]{biblatex}
\bibliography{bibliography}

\begin{document}

\title{QCE'24 Quantum Resource Estimation Educational Challenge Submission - Matrix Inversion by QSVT}
\author{Walden Killick}

\maketitle

\begin{abstract}
	We investigate the physical resources required to solve systems of linear equations using the quantum singular value transform algorithm. We find that empirically, the qubit counts scale favourably with the input size; yet the circuit runtimes do not seem to scale significantly better than classically, despite the complexity-theoretic arguments towards the contrary. We identify bottlenecks in the scaling and highlight the need for further optimisation before such quantum algorithms can outperform their classical counterparts.
\end{abstract}

\section{Introduction}

Since the breakthrough 2009 algorithm of Harrow, Hassidim, and Lloyd (HHL algorithm), it has been well-known that for sparse, well-conditioned matrices, quantum computers are capable of solving the system of linear equations (SLE) problem exponentially faster than the best possible classical algorithms \cite{harrow2009quantum}. Due to the complexities of practical implementation, the performance analyses of quantum algorithms for solving SLEs have been primarily restricted to the asymptotic regime. In this project, we aim to answer the question of what physical quantum resources are required to solve SLEs of sizes at which the problem becomes classically intractable.

On the other hand, subsequent improvements to the HHL algorithm have not received the same attention despite achieving super complexity and arguably greater conceptual simplicity. In this project, we consider the use of the quantum singular value transformation (QSVT) \cite{gilyen2019quantum, martyn2021grand} in solving systems of linear equations and investigate the physical resource requirements this entails.

All code used to generate the results in this report can  be found at \href{https://github.com/Walden-Killick/QCE24-QRE-Challenge}{https://github.com/Walden-Killick/QCE24-QRE-Challenge}.

\section{Preliminary}

\subsection{Problem definition}

Given a quantum state $\ket{b}$ and an efficient classical description of a sparse matrix $A$, the quantum linear system of equations (QSLE) problem is the problem of preparing the state $\ket{x} = A^{-1} \ket{b}$. Broadly speaking, the primary challenges in any QSLE algorithm are (1) accessing $A$ in a quantum circuit, and (2) performing (approximately) the transformation $x \mapsto 1/x$ on $A$'s eigenvalues. The HHL algorithm \cite{harrow2009quantum} achieves these goals using a sparse Hamiltonian simulation subroutine \cite{berry2007efficient} and quantum phase estimation \cite{kitaev1995quantum}, respectively. By contrast, QSVT utilises the fundamentally different techniques of block encoding \cite{gilyen2019quantum} and quantum signal processing \cite{low2017optimal} and achieves an exponentially improved dependence on the target precision as well as a lesser improvement with respect to the condtion number. We briefly review these techniques in the following subsection.

\subsection{Matrix inversion by QSVT}

To access $A$ in a quantum circuit, QSVT relies on quantum oracles which efficiently encode both the non-zero structure and non-zero elements of $A$. These are defined rigorously as follows.

\begin{definition}[Sparse access oracles \cite{camps2203explicit}]
	\label{def::sparse_access_oracles}
	Let $A$ be a $2^n \times 2^n$ $s$-sparse matrix. Let $c(j,l)$ be a function which returns the row index of the $l$-th non-zero matrix element in the $j$-th column of $A$. The sparse access oracles $O_c$ and $O_A$ for $A$ are the unitary operators defined as
	\[
		O_c \ket{l}\ket{j} = \ket{l}\ket{c(j, l)}
	\]
	and
	\[
		O_A \ket{0}\ket{l}\ket{j} = \left( A_{c(j, l), j} \ket{0} + \sqrt{1 - \abs{A_{c(j, l), j}}^2 } \ket{1} \right) \ket{l} \ket{j}.
	\]
\end{definition}

We should note that in this formalism, $O_A$ also implicitly encodes the non-zero structure of $A$ by calling $c(j, l)$; however, for certain sufficiently well-structured matrices such as those considered in this project, this is not prohibitive.

The following informal theorem states that one can construct a unitary matrix which directly contains (a scaled version of) $A$ as a submatrix (block).

\begin{theorem}[Block-encoding sparse matrices \cite{gilyen2019quantum, camps2203explicit}]
	\label{thm::block_encoding_sparse_matrices}
	Let $A, O_c, O_A$ be as in Definition \ref{def::sparse_access_oracles}. Using one call to each of $O_c$ and $O_A$, we can construct a larger unitary matrix $U_A$ for which the upper left $2^n \times 2^n$ block is equal to $A/s$.
\end{theorem}

The final ingredient in matrix inversion by QSVT is then to transform the singular values of $A/s$ as $x \mapsto 1/x$. QSVT cannot perform this transformation exactly, but can perform almost-arbitrary polynomial transformations \cite{sunderhauf2023generalized} and thus approximate $1/x$ to arbitrary precision.

\begin{theorem}[Matrix inversion by QSVT \cite{gilyen2019quantum}]
	\label{thm::matrix_inversion_by_qsvt}
	Let $A$ be a sparse matrix with condition number $\kappa$ and let $U_A$ block-encode $A$ as in Theorem \ref{thm::block_encoding_sparse_matrices}. Using $O(\kappa \log(\kappa / \varepsilon))$ calls to $U_A$ and $U_A^\dag$, we can construct a unitary which block-encodes $A^{-1}$ to within accuracy $\varepsilon$.
\end{theorem}

We refer the reader to \cite{martyn2021grand} for a pedagogical introduction to block encodings and QSVT.

\subsection{Banded circulant matrices}

To construct polynomial-size oracles $O_c$ and $O_A$, $A$ must be well-structured in some way. For this project, we consider \textit{banded circulant} matrices primarily due to the known explicit and simple construction of their sparse access oracles.

\begin{definition}[Circulant matrix]
	A circulant matrix is a matrix in which each row is equal to the previous row but with each element shifted one place to the right.
\end{definition}

\begin{definition}[Banded circulant matrix]
	A circulant matrix is banded if only the first three entries of the second row are non-zero.
\end{definition}

The following is an example of a banded circulant matrix with diagonal entries $\alpha$, sub-diagonal entries $\beta$, and super-diagonal entries $\gamma$:
\[
	\begin{bmatrix}
		\alpha & \gamma & 0 & \cdots & \beta \\
		\beta & \alpha & \gamma & \cdots & 0 \\
		0 & \beta & \alpha & \cdots & 0 \\
		\vdots & \vdots & \vdots & \ddots & \vdots \\
		\gamma & 0 & 0 & \cdots & \alpha
	\end{bmatrix}.
\]
Reference \cite{camps2203explicit} shows how to construct polynomial-size sparse-access oracles for this class of matrices, for which we show high-level sketches in Figure \ref{fig::block_encoding_circuit}. In particular, the authors show how to construct $O_A$ in $O(1)$ time and $O_c$ in $O(\text{poly}\log(N))$ time\footnote{Their construction of $O_c$ requires $n = \ceil{\log(N)}$ multi-controlled \textsc{NOT} gates with $n-1, n-2, \dots, 0$ controls. This theoretically does not prohibitively impact the complexity as such gates can be decomposed into linear-depth circuits with local gates \cite{da2022linear}.}. Combining this with Theorems \ref{thm::block_encoding_sparse_matrices} and \ref{thm::matrix_inversion_by_qsvt}, we can see that using the aforementioned construction, we can perform matrix inversion by QSVT in time $O(\kappa \, \text{poly}\log(N) \log(\kappa / \varepsilon))$, retaining the exponential quantum speedup with respect to the matrix size. This furthermore outperforms the HHL algorithm with respect to both precision and the condition number, which has a complexity of $O(\kappa^2 \log(N) / \varepsilon)$ \cite{harrow2009quantum}.

\begin{figure}
	\centering
	\begin{quantikz}[column sep = 2pt]
		& \qw & \qw & \gate{R_Y(\theta_0)}\gategroup[3, steps = 3, style = {dashed, rounded corners, inner xsep = 2pt, inner ysep = 2pt} ]{$O_A$} & \gate{R_Y(\theta_1)} & \gate{R_Y(\theta_2)} & \qw & \qw & \qw & \qw & \qw & \qw \\
		& \gate{H} & \hphantomgate{} & \octrl{-1} & \octrl{-1} & \ctrl{-1} & \qw & \qw\gategroup[3, steps = 2, style = {dashed, rounded corners, inner xsep = 2pt, inner ysep = 2pt}, label style = {label position = below, anchor = north, yshift = -6pt}]{$O_c$} & \ctrl{2} & \hphantomgate{} & \gate{H} & \qw \\
		& \gate{H} & \qw & \octrl{-1} & \ctrl{-1} & \octrl{-1} & \qw & \ctrl{1} & \qw & \qw & \gate{H} & \qw \\
		& \qwbundle{n = \ceil{\log{N}}} & \qw & \qw & \qw & \qw & \hphantomgate{} & \gate{L} & \gate{R} & \qw & \qw & \qw
	\end{quantikz}
	\caption{Quantum circuit for block-encoding an $N \times N$ banded circulant matrix, adapted from \cite{camps2203explicit}. For $n = \ceil{\log{N}}$ qubits, the $L$ and $R$ gates each consist of $n$ multi-controlled \textsc{NOT} gates with successively decreasing numbers of controls.}
	\label{fig::block_encoding_circuit}
\end{figure}

\section{Results}

The resource estimates were generated by exporting Qiskit QSVT circuits to OpenQASM 2 files and subsequently loading them into the Microsoft Azure Quantum Resource Estimator via the web portal. We are primarily concerned with observing how the resource estimates scale with the input size $N$, and thus arbitrarily assume condition number $\kappa=3$ and target accuracy $\varepsilon=0.1$ for all circuits.

\subsection{Qubit counts}

Figure \ref{fig::qre_qubits} shows how the logical and physical resource estimates scale with the input size. Whilst the logical qubit estimates conform very naturally with the expected logarithmic growth, the physical estimates scale much more erratically, most likely due to the lack of a consistent structure between problem instances when transpiling error-corrected circuits to the physical layout. In the interest of extrapolating to worst-case resource estimates, we consider the instances which outperform an instance of smaller size to be outliers (indicated with hollow markers in Figure \ref{fig::qre_qubits}). Promisingly, despite the somewhat chaotic results, the physical resource estimates nonetheless seem to likewise conform to a logarithmic growth with $N$.

The logarithmic best-fit functions, computed using NumPy's polyfit function, are as follows:
\begin{align*}
	y_\text{logical} &= 3.607 \log{N} + 15.214, \\
	y_\text{physical} &= 67769.490 \log{N} + 219131.346,
\end{align*}
where $\log$ denotes the natural logarithm.

Although highly impractical for small problem sizes due to the large constant factors, the data would seem to empirically imply that a reasonably achievable number of physical qubits will be able to tackle problems of classically intractable sizes. For example, if the extrapolation of the physical qubit requirements remains accurate for large inputs, a $10^{100}$-dimensional banded circulant matrix could be inverted using under 16 million physical qubits.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[xlabel=Matrix dimension, ylabel=Qubits, xtick={4, 32, 64, 128, 256}, width=8.75cm, height=6cm, legend style={at={(0,1)}, anchor = south west}]
			\addplot[mark=*, only marks, color=blue] coordinates{(4,20)(8,23)(16,25)(32,28)(64,30)(128,33)(256,35)};
			\addlegendentry{Logical};
			\addplot[mark=square*, only marks, color=red, thick] coordinates{(4,33.3)(8,33.435)(128,55.695)(256,59.171)};
			\addplot[mark=square, only marks, color=red, thick] coordinates{(16,28.445)(32,30.418)(64,27.366)};
			\addlegendentry{Physical ($\times 10,000$)};
			\addplot[domain = 4:256, samples=100, smooth, thick, dashed, color=blue] {3.6067376022224074*ln(x)+15.214285714285719};
			\addplot[domain = 4:256, samples=100, smooth, thick, dashed, color=red] {(67769.48978034298*ln(x)+219131.34615384619)/10000};
		\end{axis}
	\end{tikzpicture}
	\caption{Resource estimates for the logical and physical qubit requirements for matrix inversion by QSVT.}
	\label{fig::qre_qubits}
\end{figure}

\subsection{Runtimes}

Figure \ref{fig::qre_runtime} shows how the runtime estimates scale with the input size. In this case, the runtime of matrix inversion by QSVT is clearly not scaling with the ideal polylogarithmic growth.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[xlabel=Matrix dimension, ylabel=Runtime (seconds), width=8.75cm, height=6cm, legend style={at={(0,1)}, anchor = south west}]
			\addplot[mark=*, only marks, color=blue] coordinates{(4,0.106)(8,0.209)(16,0.590)(32,1)(64,4)(128,8)(256,15)};
			\addplot[domain = 4:256, samples=100, smooth, thick, dashed, color=blue] {0.06069840030772014*x - 0.27568390804597964};
		\end{axis}
	\end{tikzpicture}
	\caption{Resource estimates for the running time of matrix inversion by QSVT.}
	\label{fig::qre_runtime}
\end{figure}

\newpage

\printbibliography

\end{document}